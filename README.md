# Projet PrÃ©diction du DiabÃ¨te â€“ Pima Indians Diabetes Dataset

Ce projet a pour objectif de **prÃ©dire la prÃ©sence ou non du diabÃ¨te** chez des femmes en utilisant le dataset **Pima Indians Diabetes**.  

Il contient principalement :

- `notebooks/01_data_exploration.ipynb` â†’ exploration, nettoyage et standardisation  
- `scripts/logistic.py` â†’ entraÃ®nement et sauvegarde dâ€™un modÃ¨le de rÃ©gression logistique

---

## ğŸ“‚ Structure du projet

```text
projet-diabete/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ diabetes.csv               # Dataset original
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_data_exploration.ipynb  # Nettoyage + standardisation
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ logistic.py                # EntraÃ®nement modÃ¨le + Ã©valuation
â”œâ”€â”€ models/
â”‚   â””â”€â”€ logreg_diabetes_model.pkl  # ModÃ¨le sauvegardÃ©
â”œâ”€â”€ results/
â”‚   â””â”€â”€ accuracy_logreg.txt        # RÃ©sultats bruts
â””â”€â”€ README.md




1ï¸âƒ£ Exploration et nettoyage des donnÃ©es (01_data_exploration.ipynb)
Ã‰tapes rÃ©alisÃ©es

Chargement du dataset original

Visualisation des corrÃ©lations (heatmap)

Correction des valeurs mÃ©dicalement impossibles :

Variable	0 = rÃ©aliste ?	Pourquoi remplacer par la mÃ©diane ?	Valeurs extrÃªmes attendues
Glucose	Non	< 40â€“50 â†’ coma hypoglycÃ©mique ; 0 = mesure ratÃ©e	70â€“200 mg/dL
BloodPressure	Non	< 50â€“60 â†’ choc ; 0 = mesure impossible	80â€“140 mmHg
SkinThickness	Non (trÃ¨s rare)	Pli cutanÃ© < 7â€“8 mm trÃ¨s exceptionnel	10â€“40 mm
Insulin	Rare	Souvent non mesurÃ© â†’ valeur manquante codÃ©e en 0	2â€“300 ÂµU/mL
BMI	Non	IMC < 10 â†’ famine sÃ©vÃ¨re incompatible	18â€“45

Les valeurs 0 ont Ã©tÃ© remplacÃ©es par la mÃ©diane de chaque colonne pour garder la robustesse face aux outliers.

Gestion des outliers extrÃªmes (clipping au 1% / 99%) sur :

Insulin (> 500â€“600 trÃ¨s rare)

Pregnancies (> 13â€“14 improbable)

BMI (> 60â€“65 trÃ¨s rare)

Standardisation : moyenne = 0, Ã©cart-type = 1 pour toutes les variables explicatives

Sauvegarde du dataset nettoyÃ© â†’ diabetes_clean.csv

2ï¸âƒ£ EntraÃ®nement du modÃ¨le (logistic.py)
Ã‰tapes rÃ©alisÃ©es

Chargement du dataset nettoyÃ© (diabetes_clean.csv)

SÃ©paration train/test (80/20) â€“ random_state=42 pour reproductibilitÃ©

EntraÃ®nement dâ€™une RÃ©gression Logistique (solver='lbfgs', max_iter=1000)

Ã‰valuation sur le test set :

Accuracy

Matrice de confusion

Sauvegarde du modÃ¨le â†’ models/logreg_diabetes_model.pkl

Sauvegarde des mÃ©triques â†’ results/accuracy_logreg.txt

RÃ©sultats typiques

Accuracy â‰ˆ 75â€“80 %

Matrice de confusion typique :

[[80â€“90  15â€“25]  # Non-diabÃ©tique (0)
 [20â€“30  25â€“40]] # DiabÃ©tique (1)


Le modÃ¨le est souvent meilleur pour dÃ©tecter les non-diabÃ©tiques que les diabÃ©tiques en raison du dÃ©sÃ©quilibre des classes (~65% non-diabÃ¨te / 35% diabÃ¨te).

âš™ï¸ Reproduire le projet

Installer les dÃ©pendances :

pip install pandas scikit-learn joblib seaborn matplotlib


Lancer le notebook dâ€™exploration :

jupyter notebook notebooks/01_data_exploration.ipynb


Lancer lâ€™entraÃ®nement du modÃ¨le :

python scripts/logistic.py


Les rÃ©sultats et le modÃ¨le entraÃ®nÃ© seront sauvegardÃ©s dans results/ et models/.
